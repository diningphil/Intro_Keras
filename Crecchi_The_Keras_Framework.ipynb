{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FrancescoCrecchi/Intro_Keras/blob/master/The_Keras_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wW1w9o0lxoid"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksbeZiyRHuBZ"
   },
   "source": [
    "Before starting, make sure you have enable hardware acceleration through GPU in the notebook. In order to do this:\n",
    "\n",
    " `Edit` -> `Notebook settings` -> `Hardware Accelerator` -> `GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yGekNUkOHpb6"
   },
   "source": [
    "Download required files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4GYRsQ5uIctv"
   },
   "outputs": [],
   "source": [
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1fnM_B3BZ2-2c4brcG95p1LUYQQt0sqXU' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1fnM_B3BZ2-2c4brcG95p1LUYQQt0sqXU\" -O dset.zip && rm -rf /tmp/cookies.txt\n",
    "!unzip -q dset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzRHKXZPxCnZ"
   },
   "source": [
    "# What is it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hoPei7GxCnQ"
   },
   "source": [
    "<img src='https://drive.google.com/uc?id=11pDAM6ND7NzijoK8ZEJ_Ro9UGVj6HzAb' width='60%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t38w2NJhxCnf"
   },
   "source": [
    "Keras is a **high-level neural networks API**, written in Python and capable of running on top of TensorFlow, CNTK, or Theano.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1P1CndCWowe8pTbLsAvOEPK4Z5NQsTw35\" width=60%>\n",
    "\n",
    "It was developed with a focus on enabling **fast experimentation**: \n",
    "\n",
    "_Being able to go from idea to result with the least possible delay is key to doing good research_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLXYxqnRxCnj"
   },
   "source": [
    "# Use Keras if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "quoC1ToXxCno"
   },
   "source": [
    "If you need a Deep Learning (DL) library that:\n",
    "- Allows for **easy and fast prototyping** (through user friendliness, modularity, and extensibility).\n",
    "- Supports both **convolutional networks and recurrent networks**, as well as combinations of the two.\n",
    "- Runs seamlessly on CPU and **GPU**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gzp2ECDvxCnt"
   },
   "source": [
    "# Keras Goodness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dToUw0afxCnv"
   },
   "source": [
    "- Minimalist, highly-modular neural network library written in **python**: no separate configuration files in a declarative format!\n",
    "- Capable of running on top of either **TensorFlow/Theano and CNTK**.\n",
    "- API for **human beings**, not machines! (Right, Tensorflow?)\n",
    "- Strong **multi-GPU** support and **distributed training** support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rb2vcwLExCnz"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "McS9tTeVxCn1"
   },
   "source": [
    "# 30-secs to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BwxU6ikYxCn3"
   },
   "source": [
    "Load a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFg4m91sxCn5"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFIn-JVoxCoA"
   },
   "outputs": [],
   "source": [
    "# TODO: STANDARDIZE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X.mean(), X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqZ5sKtrxCoI"
   },
   "outputs": [],
   "source": [
    "# TODO: PERFORM 'ONE-HOT-ENCODING' OF THE LABELS OBTAINING A COLUMN VECTOR HAVING THE SAME LENGTH OF X\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y = OneHotEncoder().fit_transform(y.reshape(-1,1))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XHtLVVyxCoM"
   },
   "outputs": [],
   "source": [
    "y[:10].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yo2cfS_GxCoR"
   },
   "outputs": [],
   "source": [
    "# TODO: HOLD-OUT A TEST SET OF SIZE 0.25\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_ts.shape, y_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZyHKE5VxCoY"
   },
   "source": [
    "The core data structure of Keras is a **model**, a way to organize layers. The simplest type of model is the `Sequential` model, a **linear stack of layers**. \n",
    "\n",
    "Here is the `Sequential` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nca_sCYjxCoa"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d1MrzQFkxCof"
   },
   "source": [
    "Stacking layers is as easy as `.add()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6XNUNWHxCof"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', input_dim=4))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQkhE1gnxCon"
   },
   "source": [
    "Once your model looks good, configure its learning process with `.compile()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEO9NoI-xCop"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdMTnVZExCov"
   },
   "source": [
    "And inspect the structure of your model with `.summary()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tShTVsgxCow"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FHDQzFF1xCo0"
   },
   "source": [
    "You can now iterate on your training data in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XHr-MLdxCo0"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_tr, y_tr, epochs=30, batch_size=32, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgV_rxQ9xCo6"
   },
   "outputs": [],
   "source": [
    "# TODO: VISUALIZE TRAINING-VALIDATION CURVES\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZSu97sPxCo-"
   },
   "source": [
    "Evaluate your performance in one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X58uHzJKxCpA"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_ts, y_ts, batch_size=128)\n",
    "print(\"Test set accuracy: {0:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRZZmRoQxCpF"
   },
   "source": [
    "Or generate predictions on new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imVDPXLXxCpG"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_ts, batch_size=128)\n",
    "pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x7qyPR7-xCpJ"
   },
   "outputs": [],
   "source": [
    "model.predict_classes(X_ts, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iANHVJtSxCpO"
   },
   "source": [
    "Building a question answering system, an image classification model, a Neural Turing Machine, or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJ-yNAxMxCpQ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezixMDmPxCpR"
   },
   "source": [
    "# MNIST classification using a Multi-layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Q2HOZRNxCpS"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1lRjIAnAV9kPNMWPOcF3ub4odChbTkFwR\" max-heigth=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TklFJReqxCpV"
   },
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lp0j4uusxCpY"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EMgc91xxCpc"
   },
   "outputs": [],
   "source": [
    "# Loads the training and test data sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToIml4jgxCpl"
   },
   "outputs": [],
   "source": [
    "first_image = X_train[0, :, :]\n",
    "plt.imshow(first_image, cmap=plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAKIwLKGxCpu"
   },
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7AzB2Y9HxCp2"
   },
   "outputs": [],
   "source": [
    "# 60K training 28 x 28 (pixel) images\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5An-0h5jxCqF"
   },
   "outputs": [],
   "source": [
    "# 10K test 28 x 28 (pixel) images\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sntbh_cBxCqM"
   },
   "outputs": [],
   "source": [
    "input_dim = np.prod(X_train.shape[1:])\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixMYQNhwxCqh"
   },
   "outputs": [],
   "source": [
    "# The training and test data sets are integers, ranging from 0 to 255.\n",
    "# We reshape the training and test data sets to be matrices with 784 (= 28 * 28) features.\n",
    "X_train = X_train.reshape(60000, input_dim).astype('float32')\n",
    "X_test = X_test.reshape(10000, input_dim).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBidKTTxxCqm"
   },
   "outputs": [],
   "source": [
    "# Scales the training and test data to range between 0 and 1.\n",
    "max_value = X_train.max()\n",
    "X_train /= max_value\n",
    "X_test /= max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4gyqkPJxCqt"
   },
   "outputs": [],
   "source": [
    "# The training and test labels are integers from 0 to 9 indicating the class label\n",
    "(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xn4xTihixCqz"
   },
   "outputs": [],
   "source": [
    "# We convert the class labels to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9yUzg0vxCq2"
   },
   "source": [
    "## Multi-layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8frKJtzXxCq4"
   },
   "source": [
    "Technically, we're building a perceptron with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4cWHOeyxCq5"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(input_dim,)))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l576oIDvxCq8"
   },
   "source": [
    "Summarize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eay6zwl-xCq-"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJBYkimjxCrF"
   },
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JaswaFnOxCrH"
   },
   "outputs": [],
   "source": [
    "# Trains the model, iterating on the training data in batches of 32 in 3 epochs.\n",
    "# Using the SGD optimizer.\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=3, verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acUvxqOYxCrP"
   },
   "outputs": [],
   "source": [
    "# TODO: VISUALIZE TRAINING AND VALIDATION ACCURACY\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_AMxZW1xCrX"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGXeYPd3xCra"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test set loss: {0:.2f} -> accuracy: {1:.2f}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nj6hU9WtxCrg"
   },
   "source": [
    "## Predicting some of Held-Out Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IY4u3uQWxCrh"
   },
   "source": [
    "Choose randomly a test sample to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMDG0hE9xCrh"
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(X_test.shape[0])\n",
    "\n",
    "first_test_image = X_test[idx, :]\n",
    "pred = model.predict_classes(first_test_image[None, :])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6nPQAVNxCrn"
   },
   "outputs": [],
   "source": [
    "# TODO: VISUALIZE IMAGE WITH PREDICTION AS TITLE\n",
    "plt.imshow(first_test_image.reshape(28, 28), cmap=plt.cm.Greys)\n",
    "plt.title(str(pred))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8Ozc4dYxCrt"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWn1q5TvxCru"
   },
   "source": [
    "# MNIST classification using a Convolutional Neural Network (ConvNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7ueJS5vxCrx"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1rAe5QRDGUstZMrPirJS0hNHf3E8x_05S\" width=90%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJUa-sIfxCry"
   },
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVYHyBdoxCry"
   },
   "outputs": [],
   "source": [
    "# Loads the training and test data sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SQbdTKsxCr7"
   },
   "outputs": [],
   "source": [
    "# We reshape the training and test data sets to be a 4D tensor.\n",
    "# Dimensions: num_images x 28 x 28 x 1\n",
    "# The 1 is because we have a single channel (greyscale). If RGB color images, we'd have 3 channels.\n",
    "X_train = X_train.reshape(60000, 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(10000, 28, 28, 1).astype('float32')\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4k--qEXxCr9"
   },
   "outputs": [],
   "source": [
    "# Scales the training and test data to range between 0 and 1.\n",
    "max_value = X_train.max()\n",
    "X_train /= max_value\n",
    "X_test /= max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwMlDBqWxCsC"
   },
   "outputs": [],
   "source": [
    "# The training and test labels are integers from 0 to 9 indicating the class label\n",
    "(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZsP7kw1xCsF"
   },
   "outputs": [],
   "source": [
    "# We convert the class labels to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rU-roop-xCsK"
   },
   "source": [
    "## Convolutional Neural Net (ConvNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cIrYi8CsxCsL"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHJ3zHWQxCsN"
   },
   "source": [
    "Summarize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldlbFOT0xCsO"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qT8lte2AxCsQ"
   },
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozWDZ342xCsR"
   },
   "outputs": [],
   "source": [
    "# Trains the model, iterating on the training data in batches of 128 in 5 epochs.\n",
    "# Using the SGD optimizer.\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_hvOJ6bxCsW"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdNBbFTVxCsX"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test set accuracy: {0:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uACXHWA1xCsd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sQq-ZrixCsd"
   },
   "source": [
    "# Using a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1D5DDDHzxCse"
   },
   "source": [
    "Achieving state-of-the-art image recognition performances training a neural network model from scratch is a **very hard** task. Luckly enough, there is no need to reinvent the wheel!\n",
    "We can simply stand on the giant's shoulder by using some **pre-trained** deep neural network model in our application for image recognition or use it as an extremely powerful features extractor leaving us with just the duty of *specialize* this general-purpose model for our task at-hand!\n",
    "\n",
    "Let's pretend you are working for a smart/IoT/intelligent/etc. pets feeding bowl startup and your job is to make the bowl able to recognize cats or dogs to provide the right type of food. In other words, you need to recognize a dog from a cat the most accurate as possible. How would you do that?\n",
    "\n",
    "One possibility is to start creating a new ConvNet model from scratch as for the MNIST case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQUpuSqgxCsv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmKVamTCxCs0"
   },
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwdOXdJ6xCs4"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-BPHWlJxCs-"
   },
   "source": [
    "### Visualize some images\n",
    "\n",
    "Inspecting the dataset folder structure, it looks like this:\n",
    "\n",
    "```\n",
    "data/\n",
    "    training_set/\n",
    "        dogs/\n",
    "            dog.1.jpg\n",
    "            dog.2.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat.1.jpg\n",
    "            cat.2.jpg\n",
    "            ...\n",
    "    test_set/\n",
    "        dogs/\n",
    "            dog.1.jpg\n",
    "            dog.2.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat.1.jpg\n",
    "            cat.2.jpg\n",
    "            ...\n",
    "```\n",
    "\n",
    "thus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKgWYBN-xCs_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "fig, axes = plt.subplots(ncols=4, figsize=(10,15))\n",
    "for i in range(4):\n",
    "    if i % 2 == 0:\n",
    "        _type = 'dog'\n",
    "    else:\n",
    "        _type = 'cat'\n",
    "    axes[i].imshow(Image.open(os.path.join(DATA_DIR, \"training_set\", _type+'s', \"{0}.{1}.jpg\".format(_type, i+1))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYWzba9pxCtP"
   },
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2w4yclkgxCtP"
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WorF-xi9xCtQ"
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vACKe2r4xCtT"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZDZjwEFrxCtV"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epznVjgUxCtW"
   },
   "outputs": [],
   "source": [
    "train_data_dir = os.path.join(DATA_DIR, 'training_set')\n",
    "test_data_dir =  os.path.join(DATA_DIR, 'test_set')\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxSWCV27xCtZ"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate_generator(test_generator, steps=nb_validation_samples // batch_size)\n",
    "print(\"Test set accuracy: {0:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2syxQAMAxCtf"
   },
   "source": [
    "We have reached ~80% of accuracy with just 40 lines of code: not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paSP4eghxCtf"
   },
   "source": [
    "## Save model for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ClW34EVhxCtg"
   },
   "outputs": [],
   "source": [
    "model.save(\"cat_vs_dogs_from_scratch.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmBilCaexCti"
   },
   "outputs": [],
   "source": [
    "!ls cat*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IPL3D8ifxCtl"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZd54T0kxCtl"
   },
   "source": [
    "## Standing on the giant's shoulders!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ra-za27sxCtm"
   },
   "source": [
    "We can _stand on the giant's shoulders_ by using a state-of-the-art convolutional model as features extractor and by _fine-tune_ the last layers to perform the _cat-vs-dog_ classification task.\n",
    "\n",
    "We will use the _ResNet-50_ architecture, pre-trained on the ImageNet dataset. Because the ImageNet dataset contains several \"cat\" classes (persian cat, siamese cat...) and many \"dog\" classes among its total of 1000 classes, this model will already have learned features that are relevant to our classification problem. In fact, it is possible that merely recording the softmax predictions of the model over our data rather than the bottleneck features would be enough to solve our dogs vs. cats classification problem extremely well. However, the method we present here is more likely to generalize well to a broader range of problems, including problems featuring classes absent from ImageNet.\n",
    "\n",
    "Here's what the ResNet architecture looks like:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1AminLP0xNTlbbQ8FFKMOGRSw5oeisGqC\">\n",
    "\n",
    "Our strategy will be as follow: we will use the pre-trained convolutional part of the model as a _very_ powerful features extractor for the simple feed-forward binary classifier for distinguishing between cats and dogs images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xA4vGKp0xCto",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "IMAGE_SIZE    = (224, 224)\n",
    "NUM_CLASSES   = 2\n",
    "BATCH_SIZE    = 64  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "FREEZE_LAYERS = 2  # freeze the first this many layers for training\n",
    "NUM_EPOCHS    = 5\n",
    "WEIGHTS_FINAL = 'model-resnet50-final.h5'\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=10,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_batches = train_datagen.flow_from_directory(os.path.join(DATA_DIR, 'training_set'),\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "valid_batches = valid_datagen.flow_from_directory(os.path.join(DATA_DIR, 'test_set'),\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "\n",
    "# show class indices\n",
    "print('****************')\n",
    "for cls, idx in train_batches.class_indices.items():\n",
    "    print('Class #{} = {}'.format(idx, cls))\n",
    "print('****************')\n",
    "\n",
    "# build our classifier model based on pre-trained ResNet50:\n",
    "# 1. we don't include the top (fully connected) layers of ResNet50\n",
    "# 2. we add a DropOut layer followed by a Dense (fully connected)\n",
    "#    layer which generates softmax class score for each class\n",
    "# 3. we compile the final model using an Adam optimizer, with a\n",
    "#    low learning rate (since we are 'fine-tuning')\n",
    "net = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
    "               input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
    "\n",
    "x = net.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)\n",
    "for layer in net_final.layers[:FREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "for layer in net_final.layers[FREEZE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "net_final.compile(optimizer=Adam(lr=1e-5),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(net_final.summary())\n",
    "\n",
    "# train the model\n",
    "net_final.fit_generator(train_batches,\n",
    "                        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
    "                        validation_data = valid_batches,\n",
    "                        validation_steps = valid_batches.samples // BATCH_SIZE,\n",
    "                        epochs = NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILdR9nPPxCtp"
   },
   "outputs": [],
   "source": [
    "# save trained weights\n",
    "net_final.save(WEIGHTS_FINAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rr1rkoe6xCts"
   },
   "source": [
    "# Show time!\n",
    "\n",
    "Let's see how does the model perform on some new image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPEzkZe_xCtt"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1poVN2BQxwcoxrGK3zZyT3pbCGF_CfiZx\" width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-ABpA-WxCtu"
   },
   "source": [
    "Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WUfWVV4VxCtu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "net = load_model('model-resnet50-final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2Nq9zJxxCtw"
   },
   "source": [
    "Load a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DREtjQZxCtw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DOG\n",
    "# url = \"https://img.huffingtonpost.com/asset/5cc1e090260000340070fb57.jpeg\"\n",
    "url = \"https://www.mille-animali.com/wp/wp-content/uploads/2018/12/Jack-Russel.jpg\"\n",
    "\n",
    "# CAT\n",
    "# url = \"https://cdn.pixabay.com/photo/2018/04/20/17/18/cat-3336579__340.jpg\"\n",
    "# url = \"https://www.lastampa.it/rf/image_500/Pub/p4/2019/06/07/LaZampa/Foto/RitagliWeb/d4819b0c-8910-11e9-aa38-fcaa0c76e025_gatto_escursione001-kdYE-U11203580860820DSB-1024x576%40LaStampa.it.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zfc65yJtxCty"
   },
   "outputs": [],
   "source": [
    "!curl -o new_image.jpg $url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5LFPGhIxCt1"
   },
   "outputs": [],
   "source": [
    "!ls -lt new_image.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6EGN7NrPRRY"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('new_image.jpg', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WTm4pbuSxCt4"
   },
   "source": [
    "Let's test it on new samples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-2aOmMgxCt4"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "cls_list = ['cats', 'dogs']\n",
    "\n",
    "img = image.load_img('new_image.jpg', target_size=(img_width, img_height))\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "x = preprocess_input(x)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "pred = net.predict(x)[0]\n",
    "top_inds = pred.argsort()[::-1][:5]\n",
    "for i in top_inds:\n",
    "    print('    {:.3f}  {}'.format(pred[i], cls_list[i]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ezixMDmPxCpR",
    "TklFJReqxCpV",
    "t9yUzg0vxCq2",
    "tJBYkimjxCrF",
    "7_AMxZW1xCrX",
    "Nj6hU9WtxCrg",
    "PWn1q5TvxCru",
    "nJUa-sIfxCry",
    "rU-roop-xCsK",
    "qT8lte2AxCsQ",
    "i_hvOJ6bxCsW",
    "3sQq-ZrixCsd",
    "XmKVamTCxCs0",
    "c-BPHWlJxCs-",
    "CYWzba9pxCtP",
    "ZDZjwEFrxCtV",
    "paSP4eghxCtf",
    "dZd54T0kxCtl",
    "Rr1rkoe6xCts"
   ],
   "include_colab_link": true,
   "name": "The Keras Framework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
