{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:100px\">\n",
    "\n",
    "<div style=\"display:inline-block; width:77%; vertical-align:middle;\">\n",
    "    <div>\n",
    "        <b>Author</b>: <a href=\"http://pages.di.unipi.it/castellana/\">Daniele Castellana</a>\n",
    "    </div>\n",
    "    <div>\n",
    "        PhD student at the Univeristy of Pisa and member of the Computational Intelligence & Machine Learning Group (<a href=\"http://www.di.unipi.it/groups/ciml/\">CIML</a>)\n",
    "    </div>\n",
    "    <div>\n",
    "        <b>Mail</b>: <a href=\"mailto:daniele.castellana@di.unipi.it\">daniele.castellana@di.unipi.it</a>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"display:inline-block; width: 10%; vertical-align:middle;\">\n",
    "    <img align=\"right\" width=\"100%\" src=\"https://upload.wikimedia.org/wikipedia/it/7/72/Stemma_unipi.png\">\n",
    "</div>\n",
    "\n",
    "<div style=\"display:inline-block; width: 10%; vertical-align:middle;\">\n",
    "    <img align=\"right\" width=\"100%\" src=\"http://www.di.unipi.it/groups/ciml/Home_files/loghi/logo_ciml-restyling2018.svg\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisation and Early Stopping\n",
    "\n",
    "## Regularisation\n",
    "Constrain the learning model to avoid overfitting and help improving generalization.\n",
    "\n",
    "Regularisation add a penalization terms to the loss function that punish the model for excessive use of resources.\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Running too many epochs may overtrain the network (see previous example) and result in overfitting and perform poorly in generalization.\n",
    "\n",
    "Early stopping consists to keep a hold out validation set and use it to test accuracy after every epoch. We maintain the weights of the best performing network on the validation set and stop training when error increases beyond this value.\n",
    "\n",
    "## Data\n",
    "\n",
    "The dataset for this example originates from the UCI Machine Learning Repository. The Boston housing data was collected in 1978 and each of the 506 entries represent aggregated data about 14 features for homes from various suburbs in Boston, Massachusetts. The data have been normalised before the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set is matrix of size (323, 13).\n",
      "323 is the number of samples and 13 is the number of feature.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "# rescale values\n",
    "x_train = StandardScaler().fit(x_train).transform(x_train)\n",
    "x_test = StandardScaler().fit(x_test).transform(x_test)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
    "\n",
    "print(\"The training set is matrix of size {}.\\n\"\n",
    "      \"{} is the number of samples and {} is the number of feature.\".format(x_train.shape, x_train.shape[0], x_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a deep model with four layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = x_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,)))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    #lienar activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback functions\n",
    "A callback is a set of functions to be applied at given stages of the training procedure. We can use callbacks to get a view on internal states and statistics of the model during training. We can pass a list of callbacks (as the keyword argument callbacks) to the **.fit()** method of the Sequential or Model classes.\n",
    "\n",
    "### EarlyStopping callback\n",
    "This callback stop training when a monitored quantity has stopped improving.\n",
    "\n",
    "The most relevant arguments are:\n",
    "- **monitor**:  quantity to be monitored\n",
    "- **patience**: number of epochs with no improvement after which training will be stopped\n",
    "\n",
    "Also, we need to add another callback function to store the best parameters found during the training. We use the **ModelCheckpoint** callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Daniele Castellana\\Miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Daniele Castellana\\Miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 337.0514 - mean_absolute_error: 15.3546 - val_loss: 156.0215 - val_mean_absolute_error: 9.5315\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 156.02152, saving model to best_model_NOREG.h5\n",
      "Epoch 2/100\n",
      " - 0s - loss: 48.4415 - mean_absolute_error: 4.9663 - val_loss: 27.0723 - val_mean_absolute_error: 3.9695\n",
      "\n",
      "Epoch 00002: val_loss improved from 156.02152 to 27.07232, saving model to best_model_NOREG.h5\n",
      "Epoch 3/100\n",
      " - 0s - loss: 26.5057 - mean_absolute_error: 3.6247 - val_loss: 22.1606 - val_mean_absolute_error: 3.5827\n",
      "\n",
      "Epoch 00003: val_loss improved from 27.07232 to 22.16059, saving model to best_model_NOREG.h5\n",
      "Epoch 4/100\n",
      " - 0s - loss: 19.0553 - mean_absolute_error: 3.0180 - val_loss: 12.5404 - val_mean_absolute_error: 2.7810\n",
      "\n",
      "Epoch 00004: val_loss improved from 22.16059 to 12.54040, saving model to best_model_NOREG.h5\n",
      "Epoch 5/100\n",
      " - 0s - loss: 15.3107 - mean_absolute_error: 2.7002 - val_loss: 11.4223 - val_mean_absolute_error: 2.6922\n",
      "\n",
      "Epoch 00005: val_loss improved from 12.54040 to 11.42232, saving model to best_model_NOREG.h5\n",
      "Epoch 6/100\n",
      " - 0s - loss: 13.9236 - mean_absolute_error: 2.6606 - val_loss: 9.8146 - val_mean_absolute_error: 2.5030\n",
      "\n",
      "Epoch 00006: val_loss improved from 11.42232 to 9.81458, saving model to best_model_NOREG.h5\n",
      "Epoch 7/100\n",
      " - 0s - loss: 13.3283 - mean_absolute_error: 2.6471 - val_loss: 9.6474 - val_mean_absolute_error: 2.4714\n",
      "\n",
      "Epoch 00007: val_loss improved from 9.81458 to 9.64741, saving model to best_model_NOREG.h5\n",
      "Epoch 8/100\n",
      " - 0s - loss: 11.3889 - mean_absolute_error: 2.4387 - val_loss: 9.7797 - val_mean_absolute_error: 2.4705\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 9.64741\n",
      "Epoch 9/100\n",
      " - 0s - loss: 11.2794 - mean_absolute_error: 2.4682 - val_loss: 12.9067 - val_mean_absolute_error: 2.8098\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 9.64741\n",
      "Epoch 10/100\n",
      " - 0s - loss: 10.9734 - mean_absolute_error: 2.4731 - val_loss: 7.9688 - val_mean_absolute_error: 2.1783\n",
      "\n",
      "Epoch 00010: val_loss improved from 9.64741 to 7.96875, saving model to best_model_NOREG.h5\n",
      "Epoch 11/100\n",
      " - 0s - loss: 10.1281 - mean_absolute_error: 2.3715 - val_loss: 11.4422 - val_mean_absolute_error: 2.6121\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 7.96875\n",
      "Epoch 12/100\n",
      " - 0s - loss: 9.6682 - mean_absolute_error: 2.2818 - val_loss: 11.0058 - val_mean_absolute_error: 2.5946\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 7.96875\n",
      "Epoch 13/100\n",
      " - 0s - loss: 9.2378 - mean_absolute_error: 2.2399 - val_loss: 9.2016 - val_mean_absolute_error: 2.3042\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 7.96875\n",
      "Epoch 14/100\n",
      " - 0s - loss: 8.5252 - mean_absolute_error: 2.1572 - val_loss: 10.1573 - val_mean_absolute_error: 2.4820\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 7.96875\n",
      "Epoch 15/100\n",
      " - 0s - loss: 8.4018 - mean_absolute_error: 2.1219 - val_loss: 9.1472 - val_mean_absolute_error: 2.2297\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 7.96875\n",
      "Epoch 16/100\n",
      " - 0s - loss: 8.5965 - mean_absolute_error: 2.1498 - val_loss: 8.9841 - val_mean_absolute_error: 2.2653\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 7.96875\n",
      "Epoch 17/100\n",
      " - 0s - loss: 7.3704 - mean_absolute_error: 1.9905 - val_loss: 8.0408 - val_mean_absolute_error: 2.1328\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 7.96875\n",
      "Epoch 18/100\n",
      " - 0s - loss: 7.0673 - mean_absolute_error: 1.9616 - val_loss: 8.8990 - val_mean_absolute_error: 2.2192\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 7.96875\n",
      "Epoch 19/100\n",
      " - 0s - loss: 6.6482 - mean_absolute_error: 1.8661 - val_loss: 10.9755 - val_mean_absolute_error: 2.4687\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 7.96875\n",
      "Epoch 20/100\n",
      " - 0s - loss: 6.5615 - mean_absolute_error: 1.9838 - val_loss: 7.6332 - val_mean_absolute_error: 2.1536\n",
      "\n",
      "Epoch 00020: val_loss improved from 7.96875 to 7.63316, saving model to best_model_NOREG.h5\n",
      "Epoch 21/100\n",
      " - 0s - loss: 6.2306 - mean_absolute_error: 1.8200 - val_loss: 8.5532 - val_mean_absolute_error: 2.2549\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 7.63316\n",
      "Epoch 22/100\n",
      " - 0s - loss: 9.0287 - mean_absolute_error: 2.2767 - val_loss: 11.7138 - val_mean_absolute_error: 2.6504\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 7.63316\n",
      "Epoch 23/100\n",
      " - 0s - loss: 6.1518 - mean_absolute_error: 1.8794 - val_loss: 7.1743 - val_mean_absolute_error: 2.0655\n",
      "\n",
      "Epoch 00023: val_loss improved from 7.63316 to 7.17429, saving model to best_model_NOREG.h5\n",
      "Epoch 24/100\n",
      " - 0s - loss: 5.5330 - mean_absolute_error: 1.7301 - val_loss: 7.2148 - val_mean_absolute_error: 2.0886\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 7.17429\n",
      "Epoch 25/100\n",
      " - 0s - loss: 5.1982 - mean_absolute_error: 1.6955 - val_loss: 11.2474 - val_mean_absolute_error: 2.5838\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 7.17429\n",
      "Epoch 26/100\n",
      " - 0s - loss: 5.3590 - mean_absolute_error: 1.7048 - val_loss: 7.9068 - val_mean_absolute_error: 2.1454\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 7.17429\n",
      "Epoch 27/100\n",
      " - 0s - loss: 4.6807 - mean_absolute_error: 1.5884 - val_loss: 9.9223 - val_mean_absolute_error: 2.4306\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 7.17429\n",
      "Epoch 28/100\n",
      " - 0s - loss: 8.7244 - mean_absolute_error: 2.2566 - val_loss: 15.1673 - val_mean_absolute_error: 3.0557\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 7.17429\n",
      "Epoch 29/100\n",
      " - 0s - loss: 7.7817 - mean_absolute_error: 2.1214 - val_loss: 8.6641 - val_mean_absolute_error: 2.1916\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 7.17429\n",
      "Epoch 30/100\n",
      " - 0s - loss: 4.5044 - mean_absolute_error: 1.6082 - val_loss: 7.7289 - val_mean_absolute_error: 2.1141\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 7.17429\n",
      "Epoch 31/100\n",
      " - 0s - loss: 4.6137 - mean_absolute_error: 1.5816 - val_loss: 6.7959 - val_mean_absolute_error: 2.0832\n",
      "\n",
      "Epoch 00031: val_loss improved from 7.17429 to 6.79591, saving model to best_model_NOREG.h5\n",
      "Epoch 32/100\n",
      " - 0s - loss: 4.6648 - mean_absolute_error: 1.6336 - val_loss: 6.6568 - val_mean_absolute_error: 2.0045\n",
      "\n",
      "Epoch 00032: val_loss improved from 6.79591 to 6.65680, saving model to best_model_NOREG.h5\n",
      "Epoch 33/100\n",
      " - 0s - loss: 3.8584 - mean_absolute_error: 1.4749 - val_loss: 8.0610 - val_mean_absolute_error: 2.2073\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 6.65680\n",
      "Epoch 34/100\n",
      " - 0s - loss: 3.9668 - mean_absolute_error: 1.4824 - val_loss: 7.9918 - val_mean_absolute_error: 2.1801\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 6.65680\n",
      "Epoch 35/100\n",
      " - 0s - loss: 3.8779 - mean_absolute_error: 1.4956 - val_loss: 8.6781 - val_mean_absolute_error: 2.2718\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 6.65680\n",
      "Epoch 36/100\n",
      " - 0s - loss: 3.9397 - mean_absolute_error: 1.4761 - val_loss: 8.2901 - val_mean_absolute_error: 2.2139\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 6.65680\n",
      "Epoch 37/100\n",
      " - 0s - loss: 3.6314 - mean_absolute_error: 1.4405 - val_loss: 8.6805 - val_mean_absolute_error: 2.2734\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 6.65680\n",
      "Epoch 38/100\n",
      " - 0s - loss: 3.2061 - mean_absolute_error: 1.3158 - val_loss: 7.5370 - val_mean_absolute_error: 2.0999\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 6.65680\n",
      "Epoch 39/100\n",
      " - 0s - loss: 3.1205 - mean_absolute_error: 1.2915 - val_loss: 9.2137 - val_mean_absolute_error: 2.3549\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 6.65680\n",
      "Epoch 40/100\n",
      " - 0s - loss: 3.3103 - mean_absolute_error: 1.3721 - val_loss: 7.4525 - val_mean_absolute_error: 2.1187\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 6.65680\n",
      "Epoch 41/100\n",
      " - 0s - loss: 3.0368 - mean_absolute_error: 1.2750 - val_loss: 7.5044 - val_mean_absolute_error: 2.1487\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 6.65680\n",
      "Epoch 42/100\n",
      " - 0s - loss: 2.7853 - mean_absolute_error: 1.1818 - val_loss: 7.6284 - val_mean_absolute_error: 2.1086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_loss did not improve from 6.65680\n",
      "Epoch 00042: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', verbose=2, patience=10)\n",
    "mc = ModelCheckpoint('best_model_NOREG.h5', monitor='val_loss', verbose=2, save_best_only=True) #salva il modello su disco quando è \"buono\", inteso come minima loss sul Validation (vedi \"monitor\")\n",
    "\n",
    "model = build_model()\n",
    "h = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=10, verbose=2, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "The regularisation can be added to each layer through the argument **kernel_regularizer**.\n",
    "\n",
    "Any function that takes in a weight matrix and returns a loss contribution tensor can be used as a regularizer, but the most common are already define in keras.regularizers (see [documentation page](https://keras.io/regularizers/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def build_L2_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = x_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    #lienar activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 358.2347 - mean_absolute_error: 16.1336 - val_loss: 147.6460 - val_mean_absolute_error: 9.2396\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 147.64599, saving model to best_model_L2.h5\n",
      "Epoch 2/100\n",
      " - 0s - loss: 60.4382 - mean_absolute_error: 5.2809 - val_loss: 27.3556 - val_mean_absolute_error: 3.6569\n",
      "\n",
      "Epoch 00002: val_loss improved from 147.64599 to 27.35564, saving model to best_model_L2.h5\n",
      "Epoch 3/100\n",
      " - 0s - loss: 27.9150 - mean_absolute_error: 3.3443 - val_loss: 19.6697 - val_mean_absolute_error: 3.1456\n",
      "\n",
      "Epoch 00003: val_loss improved from 27.35564 to 19.66974, saving model to best_model_L2.h5\n",
      "Epoch 4/100\n",
      " - 0s - loss: 22.6248 - mean_absolute_error: 3.0468 - val_loss: 20.5311 - val_mean_absolute_error: 3.2463\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 19.66974\n",
      "Epoch 5/100\n",
      " - 0s - loss: 21.1956 - mean_absolute_error: 2.9941 - val_loss: 15.1182 - val_mean_absolute_error: 2.7648\n",
      "\n",
      "Epoch 00005: val_loss improved from 19.66974 to 15.11823, saving model to best_model_L2.h5\n",
      "Epoch 6/100\n",
      " - 0s - loss: 18.1281 - mean_absolute_error: 2.7429 - val_loss: 15.4833 - val_mean_absolute_error: 2.8716\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 15.11823\n",
      "Epoch 7/100\n",
      " - 0s - loss: 16.8143 - mean_absolute_error: 2.7003 - val_loss: 15.2708 - val_mean_absolute_error: 2.7969\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 15.11823\n",
      "Epoch 8/100\n",
      " - 0s - loss: 15.1896 - mean_absolute_error: 2.5743 - val_loss: 12.8658 - val_mean_absolute_error: 2.4706\n",
      "\n",
      "Epoch 00008: val_loss improved from 15.11823 to 12.86580, saving model to best_model_L2.h5\n",
      "Epoch 9/100\n",
      " - 0s - loss: 14.3568 - mean_absolute_error: 2.3969 - val_loss: 14.2461 - val_mean_absolute_error: 2.7047\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 12.86580\n",
      "Epoch 10/100\n",
      " - 0s - loss: 13.3610 - mean_absolute_error: 2.3310 - val_loss: 11.4329 - val_mean_absolute_error: 2.3437\n",
      "\n",
      "Epoch 00010: val_loss improved from 12.86580 to 11.43293, saving model to best_model_L2.h5\n",
      "Epoch 11/100\n",
      " - 0s - loss: 12.8988 - mean_absolute_error: 2.3086 - val_loss: 11.2856 - val_mean_absolute_error: 2.2840\n",
      "\n",
      "Epoch 00011: val_loss improved from 11.43293 to 11.28559, saving model to best_model_L2.h5\n",
      "Epoch 12/100\n",
      " - 0s - loss: 12.6144 - mean_absolute_error: 2.2301 - val_loss: 16.5367 - val_mean_absolute_error: 2.9100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 11.28559\n",
      "Epoch 13/100\n",
      " - 0s - loss: 11.9679 - mean_absolute_error: 2.2754 - val_loss: 11.6109 - val_mean_absolute_error: 2.3599\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 11.28559\n",
      "Epoch 14/100\n",
      " - 0s - loss: 11.5677 - mean_absolute_error: 2.1739 - val_loss: 12.2990 - val_mean_absolute_error: 2.3883\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 11.28559\n",
      "Epoch 15/100\n",
      " - 0s - loss: 12.4009 - mean_absolute_error: 2.4118 - val_loss: 13.6352 - val_mean_absolute_error: 2.5083\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 11.28559\n",
      "Epoch 16/100\n",
      " - 0s - loss: 10.2758 - mean_absolute_error: 2.0341 - val_loss: 9.7050 - val_mean_absolute_error: 2.1286\n",
      "\n",
      "Epoch 00016: val_loss improved from 11.28559 to 9.70497, saving model to best_model_L2.h5\n",
      "Epoch 17/100\n",
      " - 0s - loss: 10.4319 - mean_absolute_error: 2.0690 - val_loss: 10.6059 - val_mean_absolute_error: 2.1585\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 9.70497\n",
      "Epoch 18/100\n",
      " - 0s - loss: 9.9856 - mean_absolute_error: 1.9629 - val_loss: 9.8670 - val_mean_absolute_error: 2.1197\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 9.70497\n",
      "Epoch 19/100\n",
      " - 0s - loss: 10.5611 - mean_absolute_error: 2.0742 - val_loss: 10.5752 - val_mean_absolute_error: 2.2974\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 9.70497\n",
      "Epoch 20/100\n",
      " - 0s - loss: 10.4181 - mean_absolute_error: 2.0716 - val_loss: 10.0203 - val_mean_absolute_error: 2.1458\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 9.70497\n",
      "Epoch 21/100\n",
      " - 0s - loss: 8.7946 - mean_absolute_error: 1.7874 - val_loss: 11.1630 - val_mean_absolute_error: 2.2533\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 9.70497\n",
      "Epoch 22/100\n",
      " - 0s - loss: 8.7629 - mean_absolute_error: 1.7333 - val_loss: 11.4299 - val_mean_absolute_error: 2.2464\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 9.70497\n",
      "Epoch 23/100\n",
      " - 0s - loss: 9.2002 - mean_absolute_error: 1.7689 - val_loss: 13.5621 - val_mean_absolute_error: 2.5763\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 9.70497\n",
      "Epoch 24/100\n",
      " - 0s - loss: 8.6214 - mean_absolute_error: 1.7791 - val_loss: 11.5573 - val_mean_absolute_error: 2.3405\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 9.70497\n",
      "Epoch 25/100\n",
      " - 0s - loss: 7.8300 - mean_absolute_error: 1.6658 - val_loss: 10.1290 - val_mean_absolute_error: 2.1231\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 9.70497\n",
      "Epoch 26/100\n",
      " - 0s - loss: 8.0434 - mean_absolute_error: 1.6836 - val_loss: 11.2152 - val_mean_absolute_error: 2.2924\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 9.70497\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_L2.h5', monitor='val_loss', verbose=2, save_best_only=True)\n",
    "\n",
    "L2_model = build_L2_model()\n",
    "h_L2 = L2_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=10, verbose=2, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dropout regularizer can be applied adding a Dropout layer between two dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "def build_DROPOUT_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = x_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    #lienar activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Daniele Castellana\\Miniconda3\\envs\\keras_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 396.7631 - mean_absolute_error: 17.4770 - val_loss: 141.3688 - val_mean_absolute_error: 9.5707\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 141.36883, saving model to best_model_DROPOUT.h5\n",
      "Epoch 2/100\n",
      " - 0s - loss: 83.3330 - mean_absolute_error: 6.4330 - val_loss: 33.5355 - val_mean_absolute_error: 4.2268\n",
      "\n",
      "Epoch 00002: val_loss improved from 141.36883 to 33.53549, saving model to best_model_DROPOUT.h5\n",
      "Epoch 3/100\n",
      " - 0s - loss: 40.8571 - mean_absolute_error: 4.5012 - val_loss: 26.5573 - val_mean_absolute_error: 3.8826\n",
      "\n",
      "Epoch 00003: val_loss improved from 33.53549 to 26.55725, saving model to best_model_DROPOUT.h5\n",
      "Epoch 4/100\n",
      " - 0s - loss: 30.8188 - mean_absolute_error: 3.9241 - val_loss: 17.8233 - val_mean_absolute_error: 3.2375\n",
      "\n",
      "Epoch 00004: val_loss improved from 26.55725 to 17.82331, saving model to best_model_DROPOUT.h5\n",
      "Epoch 5/100\n",
      " - 0s - loss: 30.9302 - mean_absolute_error: 4.0411 - val_loss: 13.8150 - val_mean_absolute_error: 2.7780\n",
      "\n",
      "Epoch 00005: val_loss improved from 17.82331 to 13.81502, saving model to best_model_DROPOUT.h5\n",
      "Epoch 6/100\n",
      " - 0s - loss: 31.5682 - mean_absolute_error: 4.1213 - val_loss: 16.4685 - val_mean_absolute_error: 3.1263\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 13.81502\n",
      "Epoch 7/100\n",
      " - 0s - loss: 23.5394 - mean_absolute_error: 3.6317 - val_loss: 15.2626 - val_mean_absolute_error: 3.0573\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 13.81502\n",
      "Epoch 8/100\n",
      " - 0s - loss: 28.1709 - mean_absolute_error: 3.8708 - val_loss: 15.7217 - val_mean_absolute_error: 3.1460\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 13.81502\n",
      "Epoch 9/100\n",
      " - 0s - loss: 18.8839 - mean_absolute_error: 3.3170 - val_loss: 15.7178 - val_mean_absolute_error: 3.2328\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 13.81502\n",
      "Epoch 10/100\n",
      " - 0s - loss: 21.6966 - mean_absolute_error: 3.3515 - val_loss: 12.9510 - val_mean_absolute_error: 2.8982\n",
      "\n",
      "Epoch 00010: val_loss improved from 13.81502 to 12.95100, saving model to best_model_DROPOUT.h5\n",
      "Epoch 11/100\n",
      " - 0s - loss: 23.6898 - mean_absolute_error: 3.5750 - val_loss: 10.4364 - val_mean_absolute_error: 2.5739\n",
      "\n",
      "Epoch 00011: val_loss improved from 12.95100 to 10.43639, saving model to best_model_DROPOUT.h5\n",
      "Epoch 12/100\n",
      " - 0s - loss: 21.9726 - mean_absolute_error: 3.6412 - val_loss: 17.4544 - val_mean_absolute_error: 3.5136\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 10.43639\n",
      "Epoch 13/100\n",
      " - 0s - loss: 20.3626 - mean_absolute_error: 3.3110 - val_loss: 12.0996 - val_mean_absolute_error: 2.7374\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 10.43639\n",
      "Epoch 14/100\n",
      " - 0s - loss: 19.0976 - mean_absolute_error: 3.3478 - val_loss: 9.8732 - val_mean_absolute_error: 2.4963\n",
      "\n",
      "Epoch 00014: val_loss improved from 10.43639 to 9.87323, saving model to best_model_DROPOUT.h5\n",
      "Epoch 15/100\n",
      " - 0s - loss: 17.6277 - mean_absolute_error: 3.1146 - val_loss: 11.0552 - val_mean_absolute_error: 2.6199\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 9.87323\n",
      "Epoch 16/100\n",
      " - 0s - loss: 16.1897 - mean_absolute_error: 3.0712 - val_loss: 15.2122 - val_mean_absolute_error: 3.1633\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 9.87323\n",
      "Epoch 17/100\n",
      " - 0s - loss: 17.8489 - mean_absolute_error: 3.1432 - val_loss: 9.7528 - val_mean_absolute_error: 2.4399\n",
      "\n",
      "Epoch 00017: val_loss improved from 9.87323 to 9.75279, saving model to best_model_DROPOUT.h5\n",
      "Epoch 18/100\n",
      " - 0s - loss: 16.8112 - mean_absolute_error: 3.0829 - val_loss: 9.1130 - val_mean_absolute_error: 2.3804\n",
      "\n",
      "Epoch 00018: val_loss improved from 9.75279 to 9.11298, saving model to best_model_DROPOUT.h5\n",
      "Epoch 19/100\n",
      " - 0s - loss: 19.4570 - mean_absolute_error: 3.1295 - val_loss: 10.1023 - val_mean_absolute_error: 2.5736\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 9.11298\n",
      "Epoch 20/100\n",
      " - 0s - loss: 14.5070 - mean_absolute_error: 2.9153 - val_loss: 13.9915 - val_mean_absolute_error: 3.0046\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 9.11298\n",
      "Epoch 21/100\n",
      " - 0s - loss: 19.6754 - mean_absolute_error: 3.1847 - val_loss: 10.0793 - val_mean_absolute_error: 2.5131\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 9.11298\n",
      "Epoch 22/100\n",
      " - 0s - loss: 20.9337 - mean_absolute_error: 3.3311 - val_loss: 9.0230 - val_mean_absolute_error: 2.2792\n",
      "\n",
      "Epoch 00022: val_loss improved from 9.11298 to 9.02298, saving model to best_model_DROPOUT.h5\n",
      "Epoch 23/100\n",
      " - 0s - loss: 15.7424 - mean_absolute_error: 3.0163 - val_loss: 15.7949 - val_mean_absolute_error: 3.2298\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 9.02298\n",
      "Epoch 24/100\n",
      " - 0s - loss: 14.2505 - mean_absolute_error: 2.9189 - val_loss: 9.9439 - val_mean_absolute_error: 2.5309\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 9.02298\n",
      "Epoch 25/100\n",
      " - 0s - loss: 16.3857 - mean_absolute_error: 2.8542 - val_loss: 8.5425 - val_mean_absolute_error: 2.2749\n",
      "\n",
      "Epoch 00025: val_loss improved from 9.02298 to 8.54246, saving model to best_model_DROPOUT.h5\n",
      "Epoch 26/100\n",
      " - 0s - loss: 14.3439 - mean_absolute_error: 2.8679 - val_loss: 9.1645 - val_mean_absolute_error: 2.3603\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 8.54246\n",
      "Epoch 27/100\n",
      " - 0s - loss: 15.8129 - mean_absolute_error: 2.9183 - val_loss: 10.4289 - val_mean_absolute_error: 2.5926\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 8.54246\n",
      "Epoch 28/100\n",
      " - 0s - loss: 14.6474 - mean_absolute_error: 2.9363 - val_loss: 10.2414 - val_mean_absolute_error: 2.4691\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 8.54246\n",
      "Epoch 29/100\n",
      " - 0s - loss: 14.5089 - mean_absolute_error: 2.7304 - val_loss: 8.7995 - val_mean_absolute_error: 2.3738\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 8.54246\n",
      "Epoch 30/100\n",
      " - 0s - loss: 15.2453 - mean_absolute_error: 2.8045 - val_loss: 16.9326 - val_mean_absolute_error: 3.3703\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 8.54246\n",
      "Epoch 31/100\n",
      " - 0s - loss: 15.3834 - mean_absolute_error: 2.8753 - val_loss: 13.0650 - val_mean_absolute_error: 2.8455\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 8.54246\n",
      "Epoch 32/100\n",
      " - 0s - loss: 14.3371 - mean_absolute_error: 2.8714 - val_loss: 10.6444 - val_mean_absolute_error: 2.5439\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 8.54246\n",
      "Epoch 33/100\n",
      " - 0s - loss: 16.6007 - mean_absolute_error: 2.8512 - val_loss: 14.2880 - val_mean_absolute_error: 3.0367\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 8.54246\n",
      "Epoch 34/100\n",
      " - 0s - loss: 14.0974 - mean_absolute_error: 2.9175 - val_loss: 12.1736 - val_mean_absolute_error: 2.6671\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 8.54246\n",
      "Epoch 35/100\n",
      " - 0s - loss: 13.4373 - mean_absolute_error: 2.6833 - val_loss: 9.6210 - val_mean_absolute_error: 2.4852\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 8.54246\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_DROPOUT.h5', monitor='val_loss', verbose=2, save_best_only=True)\n",
    "\n",
    "DROPOUT_model = build_DROPOUT_model()\n",
    "h_DROPOUT = DROPOUT_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=10, verbose=2, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the best model found during the training; we use the function **load_model** from keras.models to load model saved through the ModelCheckpoint callback.\n",
    "\n",
    "Then, we evaluate the threee models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step\n",
      "102/102 [==============================] - 0s 4ms/step\n",
      "102/102 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# laod best models and test them\n",
    "from keras.models import load_model\n",
    "\n",
    "best_NOREG_model = load_model('best_model_NOREG.h5')\n",
    "best_L2_model = load_model('best_model_L2.h5')\n",
    "best_DROPOUT_model = load_model('best_model_DROPOUT.h5')\n",
    "\n",
    "test_mse_NOREG, test_mae_NOREG = best_NOREG_model.evaluate(x_test, y_test)\n",
    "test_mse_L2, test_mae_L2 = best_L2_model.evaluate(x_test, y_test)\n",
    "test_mse_DROPOUT, test_mae_DROPOUT = best_DROPOUT_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.bar([1,2,3], [test_mse_NOREG, test_mse_L2, test_mse_DROPOUT], color=['blue','red','green'])\n",
    "plt.xticks([1,2,3], ['NOREG', 'L2','DROPOUT'])\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Test MSE loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
