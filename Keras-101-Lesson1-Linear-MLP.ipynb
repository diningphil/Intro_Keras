{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 101 - Linear Model on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook, we will program simple Keras examples using the Sequential API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility libraries\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Softmax\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt # For plotting purposes\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "# Use the above import when the bug is solved\n",
    "#import keras\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "#from keras.callbacks import TensorBoard\n",
    "# ------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension (for visualization purposes)\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each MNIST image has shape (28,28)\n",
    "mnist_img_rows, mnist_img_cols = 28, 28\n",
    "dim_target = 10\n",
    "\n",
    "# Load the MNIST dataset, which has already been splitted into training and test set\n",
    "(mnist_train, mnist_y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the shape of our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 examples of (28, 28) features each value\n",
      "Training targets have shape (60000,) i.e. we will predict a constant target value for each example\n",
      "\n",
      "Test set has 10000 examples of (28, 28) features each value\n",
      "Test targets have shape (10000,) i.e. we will predict a constant target value for each example\n",
      "\n",
      "Examples have type uint8, targets have type uint8\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set has {mnist_train.shape[0]} examples of {mnist_train.shape[1:]} features each value')\n",
    "print(f'Training targets have shape {mnist_y_train.shape} i.e. we will predict a constant target value for each example')\n",
    "print('')\n",
    "print(f'Test set has {x_test.shape[0]} examples of {x_test.shape[1:]} features each value')\n",
    "print(f'Test targets have shape {y_test.shape} i.e. we will predict a constant target value for each example')\n",
    "print('')\n",
    "print(f'Examples have type {mnist_train.dtype}, targets have type {mnist_y_train.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a validation set from the training set (the Pythonic way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use scikit-learn when working with NumPy matrices. Use the ``sklearn.model_selection.train_test_split`` function (that you can use to extract a train/test split from the whole dataset and a validation set from the train set) or the ``sklearn.model_selection.KFold`` function for k-fold (external or internal) cross validation. **Remember: external cross validation is used for model assessment (average of k performances on unseen TEST data), whereas internal cross validation is used for model selection (average of k performances on VALIDATION data to select the best configuration)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subset(x_dataset, y_dataset, subset_percentage=10):\n",
    "    # Choose a seed to obtain the same split\n",
    "    random.seed(42)\n",
    "    \n",
    "    no_samples = x_dataset.shape[0]\n",
    "\n",
    "    # Generate a list of indices\n",
    "    indices = [i for i in range(no_samples)]\n",
    "\n",
    "    # We want the x% of the training set to be used as a validation set\n",
    "    no_subset_samples = int((no_samples/100)*subset_percentage)\n",
    "\n",
    "    # In place shuffling of the data structure\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    # Display the indices\n",
    "    # print(f'Validation indices are: {indices[:no_subset_samples]}')\n",
    "\n",
    "    # The subset will correspond to the first \"no_subset_samples\" shuffled indices\n",
    "    x_subset = x_dataset[indices[:no_subset_samples], :]\n",
    "    y_subset = y_dataset[indices[:no_subset_samples]]\n",
    "\n",
    "    # The rest of the data will correspond to other shuffled indices\n",
    "    new_x_dataset = x_dataset[indices[no_subset_samples:], :]\n",
    "    new_y_dataset = y_dataset[indices[no_subset_samples:]]\n",
    "    \n",
    "    return (new_x_dataset, new_y_dataset), (x_subset, y_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a validation set from the TRAINING set.\n",
    "# You can also use this function to split you entire dataset into training, validation and test sets when these are not given.\n",
    "(x_train, y_train), (x_valid, y_valid) = extract_subset(mnist_train, mnist_y_train, subset_percentage=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], -1).astype('float32') / 255\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], -1).astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], -1).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The associated target label is 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0].reshape(mnist_img_rows, mnist_img_cols), cmap='gray')\n",
    "print(f'The associated target label is {y_train[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First define the hyper-parameters of the model\n",
    "### Later, we can try to do model selection via random search on hyper-parameters ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters of the model\n",
    "l1_regularization = 0.  # L1 regularization to be applied to the weight matrix W\n",
    "l2_regularization = 1e-5  # L2 regularization to be applied to the weight matrix W\n",
    "learning_rate = 1e-3  # Learning rate\n",
    "batch_size = 64  # Mini-batch training for stochastic gradient descent\n",
    "no_epochs = 20  # Maximum number of epochs to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define a linear model with the Sequential API\n",
    "linear = Sequential()\n",
    "\n",
    "# Let's add the connection between input and output\n",
    "linear.add(Dense(units=dim_target,  # depends on the task at hand\n",
    "                 activation='linear',  # the identiy mapping (no need to use non-linearities here, it's a linear model!)\n",
    "                 use_bias=True,  # we want to implement Wx + b where b is the bias\n",
    "                 kernel_regularizer=regularizers.l1_l2(l1=l1_regularization, l2=l2_regularization)  # Regularizes the weight matrix W                 \n",
    "                 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.compile(optimizer=optimizers.SGD(lr=learning_rate),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=losses.SparseCategoricalCrossentropy(from_logits=True),  # Sparse will convert categorical labels for us in one-hot form!\n",
    "              # List of metrics to monitor\n",
    "              metrics=[metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "51968/54000 [===========================>..] - ETA: 0s - loss: 2.0164 - sparse_categorical_accuracy: 0.3449\n",
      "Epoch 00001: val_sparse_categorical_accuracy improved from -inf to 0.59167, saving model to /Users/diningphil/git/Intro_Keras/checkpoints/linear/cp.ckpt\n",
      "WARNING:tensorflow:From /Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /Users/diningphil/git/Intro_Keras/checkpoints/linear/cp.ckpt/assets\n",
      "54000/54000 [==============================] - 2s 31us/sample - loss: 2.0045 - sparse_categorical_accuracy: 0.3543 - val_loss: 1.6924 - val_sparse_categorical_accuracy: 0.5917\n",
      "Epoch 2/20\n",
      "32896/54000 [=================>............] - ETA: 0s - loss: 1.5561 - sparse_categorical_accuracy: 0.6553WARNING:tensorflow:Can save best model only with val_sparse_categorical_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-9aca35cc404d>\", line 31, in <module>\n",
      "    callbacks=[save_callback, tensorboard_callback]\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 342, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 599, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2363, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 545, in call\n",
      "    ctx=ctx)\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/diningphil/miniconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs_linear\n",
    "\n",
    "# Set up a log folder in which we will store the output to be displayed on TensorBoard\n",
    "logdir = os.path.abspath(\"logs_linear/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Chekpoint path for storing our model\n",
    "checkpoint_path = os.path.abspath(\"checkpoints/linear/cp.ckpt\")\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "# There are many possible ways to store a model, for example every n epochs. Check the documentation, very useful!\n",
    "save_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_best_only=True,  # Save only the best epoch according to valid set\n",
    "                                                 monitor=\"val_sparse_categorical_accuracy\",  # Save according to valid acc\n",
    "                                                 verbose=1,\n",
    "                                                 save_weights_only=False,  # we want to save the graph as well  \n",
    "                                                 )  \n",
    "\n",
    "# Train the Model!\n",
    "# Note: fit has also the chance to specify a validation split percentage\n",
    "print('# Fit model on training data')\n",
    "history = linear.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=no_epochs,\n",
    "                    # We pass some validation for\n",
    "                    # monitoring validation loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(x_valid, y_valid),\n",
    "                    callbacks=[save_callback, tensorboard_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6db877f210820a86\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6db877f210820a86\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize your model\n",
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model from disk (for demo purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test time! \n",
    "### We cannot change the hyper-parameters once we evaluate on test!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4995541241168976, Test Accuracy: 87.73000240325928\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=128, verbose=0)  # Verbose 0 does not show any log\n",
    "print(f'Test loss: {score[0]}, Test Accuracy: {score[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT\n",
    "## We found the TEST accuracy of our linear model. There's no turning back now, you should go to your boss to report this result.\n",
    "## If you start again changing hyper-parameters and see if it improves on TEST, that is dead wrong! You are using the TEST as a VALIDATION !!\n",
    "\n",
    "### Instead, take some more time to validate a broader range of configurations on the VALIDATION test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's classify one example from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1437a1bd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].reshape(mnist_img_rows, mnist_img_cols), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class that has maximum probability associated to the input is: 7\n"
     ]
    }
   ],
   "source": [
    "# Add a softmax activation to get probabilities\n",
    "model.add(Softmax())\n",
    "\n",
    "# Predict output\n",
    "y = model.predict(np.expand_dims(x_test[0,:], 0))\n",
    "\n",
    "print(f'The class that has maximum probability associated to the input is: {np.argmax(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Exercise time! Change the code below to train an MLP!\n",
    "## I have included a complete example with the code to perform model selection via random search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1lRjIAnAV9kPNMWPOcF3ub4odChbTkFwR\" max-heigth=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs\n",
    "!rm -rf ./logs_linear/model_selection\n",
    "\n",
    "\n",
    "# Hyper-parameters ranges of the model\n",
    "l1_regularization = 0.\n",
    "l2_regularization = (1e-3, 1e-5)\n",
    "learning_rate = (1e-3, 5e-3)\n",
    "batch_size = 64\n",
    "no_epochs = (20, 50)\n",
    "\n",
    "\n",
    "# Data structure to store the best configuration tried on the VALIDATION set\n",
    "best_config = {\"val_score\": 0.,\n",
    "               \"l1_regularization\": None,\n",
    "               \"l2_regularization\": None,\n",
    "               \"learning_rate\": None,\n",
    "               \"batch_size\": None,\n",
    "               \"no_epochs\": None,\n",
    "               \"config_id\": None,\n",
    "               }\n",
    "\n",
    "no_random_searches = 5\n",
    "\n",
    "for i in range(no_random_searches):\n",
    "    \n",
    "    # Select a random configuration\n",
    "    l2 = random.uniform(l2_regularization[0], l2_regularization[1])\n",
    "    lr = random.uniform(learning_rate[0], learning_rate[1])\n",
    "    epochs = random.randint(no_epochs[0], no_epochs[1])\n",
    "    \n",
    "    # We will define a linear model with the Sequential API\n",
    "    model = Sequential()\n",
    "\n",
    "    # Let's add the connection between input and output\n",
    "    model.add(Dense(units=dim_target,  # depends on the task at hand\n",
    "                     activation='linear',  # the identiy mapping (no need to use non-linearities here, it's a linear model!)\n",
    "                     use_bias=True,  # we want to implement Wx + b where b is the bias\n",
    "                     kernel_regularizer=regularizers.l1_l2(l1=l1_regularization, l2=l2)  # Regularizes the weight matrix W                 \n",
    "                     ))\n",
    "    \n",
    "    model.compile(optimizer=optimizers.SGD(lr=lr),  # Optimizer\n",
    "                   # Loss function to minimize\n",
    "                   loss=losses.SparseCategoricalCrossentropy(from_logits=True),  # Sparse will convert categorical labels for us in one-hot form!\n",
    "                   # List of metrics to monitor\n",
    "                   metrics=[metrics.sparse_categorical_accuracy])\n",
    "\n",
    "\n",
    "    # Set up a log folder in which we will store the output to be displayed on TensorBoard\n",
    "    logdir = os.path.abspath(f\"logs_linear/model_selection/config_{i}/fit/\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # Train the Model!\n",
    "    # Note: fit has also the chance to specify a validation split percentage\n",
    "    print('# Fit model on training data')\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        # We pass some validation for\n",
    "                        # monitoring validation loss and metrics\n",
    "                        # at the end of each epoch\n",
    "                        validation_data=(x_valid, y_valid),\n",
    "                        callbacks=[tensorboard_callback]\n",
    "                        )\n",
    "    \n",
    "    score = model.evaluate(x_valid, y_valid, batch_size=128, verbose=0)  # Verbose 0 does not show any log\n",
    "    print(f'Validation loss: {score[0]}, Validation Accuracy: {score[1]*100}')\n",
    "    \n",
    "    if score[1]*100 >= best_config['val_score']:\n",
    "        best_config['val_score'] = score[1]*100\n",
    "        best_config['l1_regularization'] = l1_regularization\n",
    "        best_config['l2_regularization'] = l2\n",
    "        best_config['learning_rate'] = lr\n",
    "        best_config['no_epochs'] = no_epochs\n",
    "        best_config['batch_size'] = batch_size\n",
    "        best_config['config_id'] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cool! We automatically found our best candidate :) now test it on test! Then there's no turning back ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your winning model\n",
    "%tensorboard --logdir ./logs_linear/model_selection/config_{best_config[\"config_id\"]}/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=128, verbose=0)  # Verbose 0 does not show any log\n",
    "print(f'Test loss: {score[0]}, Test Accuracy: {score[1]*100}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
