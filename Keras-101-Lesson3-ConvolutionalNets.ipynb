{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit to Francesco Crecchi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification using a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Utility libraries\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Softmax, Conv2D, MaxPooling2D, Dropout, Flatten, UpSampling2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt # For plotting purposes\n",
    "\n",
    "\n",
    "# Bug still not solved, resort to old keras module (see below)\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "# Use the above import when the bug is solved\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "# ------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension (for visualization purposes)\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJUa-sIfxCry"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVYHyBdoxCry"
   },
   "outputs": [],
   "source": [
    "# Loads the training and test data sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SQbdTKsxCr7"
   },
   "outputs": [],
   "source": [
    "# We reshape the training and test data sets to be a 4D tensor.\n",
    "# Dimensions: num_images x 28 x 28 x no_channels (e.g. RGB)\n",
    "# The 1 is because we have a single channel (greyscale). If RGB color images, we'd have 3 channels.\n",
    "# -1 means \"let the library infer the dimension\"\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32')\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data (scale all values between 0 and 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: you MUST NOT use statistics coming from the TEST set. That is \"cheating\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4k--qEXxCr9"
   },
   "outputs": [],
   "source": [
    "# Scales the training and test data to range between 0 and 1.\n",
    "max_value = X_train.max()\n",
    "X_train /= max_value\n",
    "X_test /= max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwMlDBqWxCsC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 0, 4, ..., 5, 6, 8], dtype=uint8),\n",
       " array([7, 2, 1, ..., 4, 5, 6], dtype=uint8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The training and test labels are integers from 0 to 9 indicating the class label\n",
    "(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We convert the class labels to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rU-roop-xCsK"
   },
   "source": [
    "## Define a Convolutional Neural Net (ConvNet) with the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7ueJS5vxCrx"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1rAe5QRDGUstZMrPirJS0hNHf3E8x_05S\" width=90%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cIrYi8CsxCsL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 10)        260       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 20)          5020      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               32100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 38,390\n",
      "Trainable params: 38,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer. Outputs 10 different \"filtered\" images (using 10 different 5x5 kernels)\n",
    "model.add(Conv2D(10, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "# Reduce the dimension of the filtered images by 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer. Outputs 20 different filters (using 20 different 5x5 kernels)\n",
    "model.add(Conv2D(20, (5, 5), activation='relu'))\n",
    "\n",
    "# Reduce the dimension of the filtered images by 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout is a technique that regularizes the model, by randomly \"turning off\" a percentage of the neurons\n",
    "# Here, we randomly shut down 75% of the neurons at each training step\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Convert the Dropout output in vectorial form\n",
    "model.add(Flatten())\n",
    "\n",
    "# Apply an MLP to the vectorial representation\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Output class probability scores\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Have you noticed the number of parameters?? 40k of CNN vs 200K of an MLP!!!\n",
    "## (32K only for final MLP)\n",
    "## Moreover, the CNN architecture extracts *local* patches of an image, whereas an MLP combines all pixels together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qT8lte2AxCsQ"
   },
   "source": [
    "## Train Classifier (we won't do model selection today, do it as an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozWDZ342xCsR",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 10s 230us/sample - loss: 1.8044 - accuracy: 0.4115 - val_loss: 0.6291 - val_accuracy: 0.8455\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 11s 248us/sample - loss: 0.5737 - accuracy: 0.8201 - val_loss: 0.3046 - val_accuracy: 0.9117\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 11s 253us/sample - loss: 0.3771 - accuracy: 0.8840 - val_loss: 0.2328 - val_accuracy: 0.9299\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 12s 261us/sample - loss: 0.2993 - accuracy: 0.9089 - val_loss: 0.1945 - val_accuracy: 0.9415\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 11s 255us/sample - loss: 0.2524 - accuracy: 0.9227 - val_loss: 0.1700 - val_accuracy: 0.9488\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 12s 256us/sample - loss: 0.2232 - accuracy: 0.9324 - val_loss: 0.1525 - val_accuracy: 0.9549\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 12s 264us/sample - loss: 0.2022 - accuracy: 0.9382 - val_loss: 0.1430 - val_accuracy: 0.9573\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 13s 289us/sample - loss: 0.1881 - accuracy: 0.9422 - val_loss: 0.1312 - val_accuracy: 0.9599\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 11s 242us/sample - loss: 0.1735 - accuracy: 0.9466 - val_loss: 0.1223 - val_accuracy: 0.9625\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 10s 228us/sample - loss: 0.1642 - accuracy: 0.9506 - val_loss: 0.1177 - val_accuracy: 0.9631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10e5b6890>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs_linear\n",
    "\n",
    "# Set up a log folder in which we will store the output to be displayed on TensorBoard\n",
    "logdir = os.path.abspath(\"logs_cnn/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Trains the model, iterating on the training data in batches of 128 in 5 epochs.\n",
    "# Using the SGD optimizer.\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# We will automatically create a validation split (less flexible for model selection)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.25,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e437813327c0852c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e437813327c0852c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6008;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize your model\n",
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_hvOJ6bxCsW"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdNBbFTVxCsX"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test set accuracy: {0:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uACXHWA1xCsd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sQq-ZrixCsd"
   },
   "source": [
    "# Using a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1D5DDDHzxCse"
   },
   "source": [
    "Achieving state-of-the-art image recognition performances training a neural network model from scratch is a **very hard** task. Luckly enough, there is no need to reinvent the wheel!\n",
    "We can simply stand on the giant's shoulder by using some **pre-trained** deep neural network model in our application for image recognition or use it as an extremely powerful features extractor leaving us with just the duty of *specialize* this general-purpose model for our task at-hand!\n",
    "\n",
    "Let's pretend you are working for a smart/IoT/intelligent/etc. pets feeding bowl startup and your job is to make the bowl able to recognize cats or dogs to provide the right type of food. In other words, you need to recognize a dog from a cat the most accurate as possible. How would you do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZd54T0kxCtl"
   },
   "source": [
    "## Standing on the giant's shoulders!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ra-za27sxCtm"
   },
   "source": [
    "We can _stand on the giant's shoulders_ by using a state-of-the-art convolutional model as features extractor and by _fine-tune_ the last layers to perform the _cat-vs-dog_ classification task.\n",
    "\n",
    "We will use the _ResNet-50_ architecture, pre-trained on the ImageNet dataset. Because the ImageNet dataset contains several \"cat\" classes (persian cat, siamese cat...) and many \"dog\" classes among its total of 1000 classes, this model will already have learned features that are relevant to our classification problem. In fact, it is possible that merely recording the softmax predictions of the model over our data rather than the bottleneck features would be enough to solve our dogs vs. cats classification problem extremely well. However, the method we present here is more likely to generalize well to a broader range of problems, including problems featuring classes absent from ImageNet.\n",
    "\n",
    "Here's what the ResNet architecture looks like:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1AminLP0xNTlbbQ8FFKMOGRSw5oeisGqC\">\n",
    "\n",
    "Our strategy will be as follow: we will use the pre-trained convolutional part of the model as a _very_ powerful features extractor for the simple feed-forward binary classifier for distinguishing between cats and dogs images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder for Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FCN](https://missinglink.ai/wp-content/uploads/2019/03/SegNet-neural-network_2x.png)\n",
    "\n",
    "### Taken from [here](https://missinglink.ai/guides/computer-vision/image-segmentation-deep-learning-methods-applications/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will use the Membrane dataset taken from [here](https://github.com/zhixuhao/unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "# Let's load all train images and put them into the right format\n",
    "train_path = os.path.abspath('membrane/train/image')\n",
    "train_y_path = os.path.abspath('membrane/train/label')\n",
    "\n",
    "test_path = os.path.abspath('membrane/test/')\n",
    "\n",
    "\n",
    "def build_dataset(path, y_path=None):\n",
    "    \n",
    "    x_data = None\n",
    "    y_data = None\n",
    "\n",
    "    for image_file in sorted([f for f in os.listdir(path) if '.png' in f]):\n",
    "\n",
    "        x = imread(os.path.join(path, image_file))\n",
    "\n",
    "        if y_path is not None:\n",
    "            y = imread(os.path.join(y_path, image_file))\n",
    "\n",
    "        if x_data is None:\n",
    "            x_data = np.expand_dims(x, axis=(0,-1))  # add batch and channel dimensions\n",
    "            if y_path is not None:\n",
    "                y_data = np.expand_dims(y, axis=(0))  # add batch dimension, we do not need a channel\n",
    "        else:\n",
    "            x_data = np.concatenate((x_data, np.expand_dims(x, axis=(0,-1))), axis=0)\n",
    "            if y_path is not None:\n",
    "                y_data = np.concatenate((y_data, np.expand_dims(y, axis=(0))), axis=0)\n",
    "\n",
    "    # Plot the last image and label\n",
    "    plt.figure()\n",
    "    plt.imshow(x, cmap='gray')\n",
    "    if y_path is not None:\n",
    "        plt.figure()\n",
    "        plt.imshow(y, cmap='gray')\n",
    "    \n",
    "    if y_path is not None:\n",
    "        y_data = y_data.astype('uint8')\n",
    "    \n",
    "    return x_data, y_data\n",
    "\n",
    "x_train, y_train = build_dataset(train_path, train_y_path)\n",
    "x_test, _ = build_dataset(test_path)\n",
    "\n",
    "\n",
    "print(f'Final shape of train dataset is: x -> {x_train.shape} and y -> {y_train.shape}')\n",
    "print(f'Final shape of test dataset is: x -> {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer. Outputs 10 different \"filtered\" images (using 10 different 5x5 kernels)\n",
    "model.add(Conv2D(20, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(512,512,1), padding=\"same\"))\n",
    "\n",
    "# Reduce the dimension of the filtered images by 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer. Outputs 20 different filters (using 20 different 5x5 kernels)\n",
    "model.add(Conv2D(30, (3, 3), activation='relu', padding=\"same\"))\n",
    "\n",
    "# Reduce the dimension of the filtered images by 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a convolutional layer. Outputs 20 different filters (using 20 different 5x5 kernels)\n",
    "model.add(Conv2D(30, (3, 3), activation='relu', padding=\"same\"))\n",
    "\n",
    "# Increase the dimension of the filtered images by 2\n",
    "model.add(UpSampling2D((2, 2), interpolation='bilinear'))\n",
    "\n",
    "# Add a convolutional layer. Outputs 20 different filters (using 20 different 5x5 kernels)\n",
    "model.add(Conv2D(20, (3, 3), activation='relu', padding=\"same\"))\n",
    "\n",
    "# Increase the dimension of the filtered images by 2\n",
    "model.add(UpSampling2D((2, 2), interpolation='bilinear'))\n",
    "\n",
    "# Add a convolutional layer. Outputs 20 different filters (using 20 different 5x5 kernels)\n",
    "model.add(Conv2D(1, (3, 3), activation='linear', padding=\"same\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=learning_rate),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=losses.BinaryCrossentropy(from_logits=False)\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model!\n",
    "# Note: fit has also the chance to specify a validation split percentage\n",
    "print('# Fit model on training data')\n",
    "history = model.fit(x_train, np.reshape(y_train, (-1, 512*512)),\n",
    "                    batch_size=2,\n",
    "                    epochs=100,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = np.reshape(model.predict(x_train), (-1, 512,512))\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0, :, :, 0], cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(y_train[0], cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(np.round(pred_train[0]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = np.reshape(model.predict(x_test), (-1, 512,512))\n",
    "plt.figure()\n",
    "plt.imshow(x_test[0, :, :, 0], cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(pred_test[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Convolutional Auto-Encoders for Anomaly Detection\n",
    "## You can reuse today's fully convolutional net and yesterday anomaly detection code to perform anomaly detection with convolutional nets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ezixMDmPxCpR",
    "TklFJReqxCpV",
    "t9yUzg0vxCq2",
    "tJBYkimjxCrF",
    "7_AMxZW1xCrX",
    "Nj6hU9WtxCrg",
    "PWn1q5TvxCru",
    "nJUa-sIfxCry",
    "rU-roop-xCsK",
    "qT8lte2AxCsQ",
    "i_hvOJ6bxCsW",
    "3sQq-ZrixCsd",
    "XmKVamTCxCs0",
    "c-BPHWlJxCs-",
    "CYWzba9pxCtP",
    "ZDZjwEFrxCtV",
    "paSP4eghxCtf",
    "dZd54T0kxCtl",
    "Rr1rkoe6xCts"
   ],
   "include_colab_link": true,
   "name": "The Keras Framework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
